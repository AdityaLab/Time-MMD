{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pygrinder import (\n",
    "    mcar,\n",
    "    mar_logistic,\n",
    "    mnar_x,\n",
    "    mnar_t,\n",
    "    rdo,\n",
    "    seq_missing,\n",
    "    block_missing,\n",
    "    calc_missing_rate\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyGrinder is a well-adopted Python toolbox for creating missing values for time-series data. It supports 3 missing patterns (points, sequences, blocks), various missing rates. Please check https://github.com/WenjieDu/PyPOTS?tab=readme-ov-file for further usecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.21686 1.28064 1.23906 ... 2.23984 2.1417  2.03183]\n"
     ]
    }
   ],
   "source": [
    "# load our numerical time series data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_csv_to_numpy_array(file_path, column_name='OT'):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    \n",
    "    column_data = df[column_name]\n",
    "    \n",
    "    return column_data.to_numpy()\n",
    "file_path=\"../../numerical/Health_US/Health_US.csv\"\n",
    "result_array = read_csv_to_numpy_array(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our numerical time series data\n",
    "ts_dataset=result_array.reshape(1,1,-1)\n",
    "# grind the dataset with MCAR pattern, 10% missing probability, and using 0 to fill missing values\n",
    "X_with_mcar_data = mcar(ts_dataset, p=0.1)\n",
    "\n",
    "# # grind the dataset with MAR pattern\n",
    "# X_with_mar_data = mar_logistic(ts_dataset[:, 0, :], obs_rate=0.1, missing_rate=0.1)\n",
    "\n",
    "# # grind the dataset with MNAR pattern\n",
    "# X_with_mnar_x_data = mnar_x(ts_dataset, offset=0.1)\n",
    "# X_with_mnar_t_data = mnar_t(ts_dataset, cycle=20, pos=10, scale=3)\n",
    "\n",
    "# # grind the dataset with RDO pattern\n",
    "# X_with_rdo_data = rdo(ts_dataset, p=0.1)\n",
    "\n",
    "# # grind the dataset with Sequence-Missing pattern\n",
    "# X_with_seq_missing_data = seq_missing(ts_dataset, p=0.1, seq_len=5)\n",
    "\n",
    "# # grind the dataset with Block-Missing pattern\n",
    "# X_with_block_missing_data = block_missing(ts_dataset, factor=0.1, block_width=3, block_len=3)\n",
    "\n",
    "# calculate the missing rate of the dataset\n",
    "missing_rate = calc_missing_rate(X_with_mcar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1101511879049676\n"
     ]
    }
   ],
   "source": [
    "print(missing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.21686     nan 1.23906 ... 2.23984 2.1417      nan]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_with_mcar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViTST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
